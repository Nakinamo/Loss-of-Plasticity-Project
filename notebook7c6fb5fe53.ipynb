{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!conda install -y gdown","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-01T20:24:26.384834Z","iopub.execute_input":"2023-10-01T20:24:26.385676Z","iopub.status.idle":"2023-10-01T20:26:27.541926Z","shell.execute_reply.started":"2023-10-01T20:24:26.385643Z","shell.execute_reply":"2023-10-01T20:26:27.540843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown https://github.com/shibhansh/loss-of-plasticity/archive/refs/heads/main.zip","metadata":{"execution":{"iopub.status.busy":"2023-10-01T20:26:27.544028Z","iopub.execute_input":"2023-10-01T20:26:27.545061Z","iopub.status.idle":"2023-10-01T20:26:31.101018Z","shell.execute_reply.started":"2023-10-01T20:26:27.545025Z","shell.execute_reply":"2023-10-01T20:26:31.099886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!echo \"A\" | unzip /kaggle/working/main.zip -d /kaggle/working/\n!mkdir /kaggle/working/lop\n!mkdir /kaggle/working/data/\n!mv /kaggle/working/loss-of-plasticity-main/* /kaggle/working/lop/","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-10-01T20:26:31.102693Z","iopub.execute_input":"2023-10-01T20:26:31.103066Z","iopub.status.idle":"2023-10-01T20:26:35.175102Z","shell.execute_reply.started":"2023-10-01T20:26:31.103032Z","shell.execute_reply":"2023-10-01T20:26:35.173710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nimport json\nimport torch\nimport pickle\nimport argparse\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport keras.utils as image\nfrom tqdm import tqdm\nfrom torch.nn.functional import softmax\nfrom glob import glob","metadata":{"execution":{"iopub.status.busy":"2023-10-01T20:26:35.178417Z","iopub.execute_input":"2023-10-01T20:26:35.182423Z","iopub.status.idle":"2023-10-01T20:26:45.583828Z","shell.execute_reply.started":"2023-10-01T20:26:35.182374Z","shell.execute_reply":"2023-10-01T20:26:45.582828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/working/lop/')\nsys.path.append('/kaggle/input')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T20:26:45.585270Z","iopub.execute_input":"2023-10-01T20:26:45.586123Z","iopub.status.idle":"2023-10-01T20:26:45.590757Z","shell.execute_reply.started":"2023-10-01T20:26:45.586086Z","shell.execute_reply":"2023-10-01T20:26:45.589829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from lop.algos.bp import Backprop\nfrom lop.nets.conv_net import ConvNet\nfrom lop.algos.convCBP import ConvCBP\nfrom lop.nets.linear import MyLinear\nfrom lop.utils.miscellaneous import nll_accuracy as accuracy","metadata":{"execution":{"iopub.status.busy":"2023-10-01T20:26:45.592306Z","iopub.execute_input":"2023-10-01T20:26:45.593132Z","iopub.status.idle":"2023-10-01T20:26:45.645792Z","shell.execute_reply.started":"2023-10-01T20:26:45.593100Z","shell.execute_reply":"2023-10-01T20:26:45.644470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport copy\nimport subprocess\nimport itertools","metadata":{"execution":{"iopub.status.busy":"2023-10-01T20:26:45.646925Z","iopub.execute_input":"2023-10-01T20:26:45.647230Z","iopub.status.idle":"2023-10-01T20:26:45.653872Z","shell.execute_reply.started":"2023-10-01T20:26:45.647190Z","shell.execute_reply":"2023-10-01T20:26:45.652301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport pickle\nimport torchvision\nimport torchvision.transforms as transforms\n\ndef mnist():\n    batch_size = 60000\n    transform = transforms.Compose(\n        [transforms.ToTensor()])\n\n    train_dataset = torchvision.datasets.MNIST(\n        root=\"data\", train=True, transform=transform, download=True\n    )\n    test_dataset = torchvision.datasets.MNIST(\n        root=\"data\", train=False, transform=transform\n    )\n    # Data loader\n    train_loader = torch.utils.data.DataLoader(\n        dataset=train_dataset, batch_size=batch_size, shuffle=True, generator=torch.Generator(device='cpu')\n\n    )\n    test_loader = torch.utils.data.DataLoader(\n        dataset=test_dataset, batch_size=batch_size, shuffle=False, generator=torch.Generator(device='cpu')\n    )\n\n    for i, (images, labels) in enumerate(train_loader):\n        images = images.flatten(start_dim=1)\n        labels = labels\n\n    x = images\n    y = labels\n\n    for i, (images_test, labels_test) in enumerate(test_loader):\n        images_test = images_test.flatten(start_dim=1)\n        labels_test = labels_test\n\n    x_test = images_test\n    y_test = labels_test\n\n    with open('data/mnist_', 'wb+') as f:\n        pickle.dump([x, y, x_test, y_test], f)\n\n    return x, y, x_test, y_test\n\n\ndef get_mnist(type='reg'):\n    if type == 'reg':\n        data_file = 'data/mnist_'\n        with open(data_file, 'rb+') as f:\n            x, y, x_test, y_test = pickle.load(f)\n    return x, y, x_test, y_test\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T20:26:45.654735Z","iopub.execute_input":"2023-10-01T20:26:45.655227Z","iopub.status.idle":"2023-10-01T20:26:45.902320Z","shell.execute_reply.started":"2023-10-01T20:26:45.655187Z","shell.execute_reply":"2023-10-01T20:26:45.901443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mnist()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T20:26:45.903754Z","iopub.execute_input":"2023-10-01T20:26:45.904293Z","iopub.status.idle":"2023-10-01T20:26:54.957168Z","shell.execute_reply.started":"2023-10-01T20:26:45.904260Z","shell.execute_reply":"2023-10-01T20:26:54.956202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from lop.utils.miscellaneous import get_configurations\n\ndef gen_cfg(cfg_file):\n\n    with open(cfg_file, 'r') as f:\n        params = json.load(f)\n\n    list_params, hyper_param_settings = get_configurations(params=params)\n\n    # make a directory for temp cfg files\n    bash_command = \"mkdir -p temp_cfg/\"\n    subprocess.Popen(bash_command.split(), stdout=subprocess.PIPE)\n\n    bash_command = \"rm -r --force \" + params['data_dir']\n    subprocess.Popen(bash_command.split(), stdout=subprocess.PIPE)\n    bash_command = \"mkdir \" + params['data_dir']\n    subprocess.Popen(bash_command.split(), stdout=subprocess.PIPE)\n\n    \"\"\"\n        Set and write all the parameters for the individual config files\n    \"\"\"\n    for setting_index, param_setting in enumerate(hyper_param_settings):\n        new_params = copy.deepcopy(params)\n        for idx, param in enumerate(list_params):\n            new_params[param] = param_setting[idx]\n        new_params['index'] = setting_index\n        new_params['data_dir'] = params['data_dir'] + str(setting_index) + '/'\n\n        \"\"\"\n            Make the data directory\n        \"\"\"\n        bash_command = \"mkdir -p \" + new_params['data_dir']\n        subprocess.Popen(bash_command.split(), stdout=subprocess.PIPE)\n\n        for idx in tqdm(range(params['num_runs'])):\n            new_params['data_file'] = new_params['data_dir'] + str(idx)\n\n            \"\"\"\n                write data in config files\n            \"\"\"\n            new_cfg_file = 'temp_cfg/'+str(setting_index*params['num_runs']+idx)+'.json'\n            try:    f = open(new_cfg_file, 'w+')\n            except: f = open(new_cfg_file, 'w+')\n            with open(new_cfg_file, 'w+') as f:\n                json.dump(new_params, f, sort_keys=False, indent=4)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T20:26:54.958756Z","iopub.execute_input":"2023-10-01T20:26:54.959436Z","iopub.status.idle":"2023-10-01T20:26:54.968025Z","shell.execute_reply.started":"2023-10-01T20:26:54.959401Z","shell.execute_reply":"2023-10-01T20:26:54.967138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_cfg('/kaggle/working/lop/lop/permuted_mnist/cfg/bp/std_net.json')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T12:43:24.947092Z","iopub.execute_input":"2023-09-28T12:43:24.948558Z","iopub.status.idle":"2023-09-28T12:43:25.005990Z","shell.execute_reply.started":"2023-09-28T12:43:24.948521Z","shell.execute_reply":"2023-09-28T12:43:25.005012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from lop.algos.bp import Backprop\nfrom lop.algos.cbp import ContinualBackprop\nfrom lop.nets.linear import MyLinear\nfrom torch.nn.functional import softmax\nfrom lop.nets.deep_ffnn import DeepFFNN\nfrom lop.utils.miscellaneous import nll_accuracy, compute_matrix_rank_summaries\n\n\ndef online_expr(params: {}):\n    agent_type = params['agent']\n    num_tasks = 60\n#     if 'num_tasks' in params.keys():\n#         num_tasks = params['num_tasks']\n#     if 'num_examples' in params.keys() and \"change_after\" in params.keys():\n#         num_tasks = int(params[\"num_examples\"]/params[\"change_after\"])\n\n    step_size = params['step_size']\n    opt = params['opt']\n    weight_decay = 0\n    use_gpu = 0\n    dev = 'cpu'\n    to_log = False\n    num_features = 2000\n    change_after = 10 * 6000\n    to_perturb = False\n    perturb_scale = 0.1\n    num_hidden_layers = 1\n    mini_batch_size = 1\n    replacement_rate = 0.0001\n    decay_rate = 0.99\n    maturity_threshold = 100\n    util_type = 'adaptable_contribution'\n\n    if 'to_log' in params.keys():\n        to_log = params['to_log']\n    if 'weight_decay' in params.keys():\n        weight_decay = params['weight_decay']\n    if 'num_features' in params.keys():\n        num_features = params['num_features']\n    if 'change_after' in params.keys():\n        change_after = params['change_after']\n    if 'use_gpu' in params.keys():\n        if params['use_gpu'] == 1:\n            use_gpu = 1\n            dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n            if dev == torch.device(\"cuda\"):    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n    if 'to_perturb' in params.keys():\n        to_perturb = params['to_perturb']\n    if 'perturb_scale' in params.keys():\n        perturb_scale = params['perturb_scale']\n    if 'num_hidden_layers' in params.keys():\n        num_hidden_layers = params['num_hidden_layers']\n    if 'mini_batch_size' in params.keys():\n        mini_batch_size = params['mini_batch_size']\n    if 'replacement_rate' in params.keys():\n        replacement_rate = params['replacement_rate']\n    if 'decay_rate' in params.keys():\n        decay_rate = params['decay_rate']\n    if 'maturity_threshold' in params.keys():\n        maturity_threshold = params['mt']\n    if 'util_type' in params.keys():\n        util_type = params['util_type']\n\n    classes_per_task = 10\n    images_per_class = 6000\n    input_size = 784\n    num_hidden_layers = num_hidden_layers\n    net = DeepFFNN(input_size=input_size, num_features=num_features, num_outputs=classes_per_task,\n                   num_hidden_layers=num_hidden_layers)\n\n    if agent_type == 'linear':\n        net = MyLinear(\n            input_size=input_size, num_outputs=classes_per_task\n        )\n        net.layers_to_log = []\n\n    if agent_type in ['bp', 'linear', \"l2\"]:\n        learner = Backprop(\n            net=net,\n            step_size=step_size,\n            opt=opt,\n            loss='nll',\n            weight_decay=weight_decay,\n            device=dev,\n            to_perturb=to_perturb,\n            perturb_scale=perturb_scale,\n        )\n    elif agent_type in ['cbp']:\n        learner = ContinualBackprop(\n            net=net,\n            step_size=step_size,\n            opt=opt,\n            loss='nll',\n            replacement_rate=replacement_rate,\n            maturity_threshold=maturity_threshold,\n            decay_rate=decay_rate,\n            util_type=util_type,\n            accumulate=True,\n            device=dev,\n        )\n\n    accuracy = nll_accuracy\n    examples_per_task = images_per_class * classes_per_task\n    total_examples = int(num_tasks * change_after)\n    total_iters = int(total_examples/mini_batch_size)\n    save_after_every_n_tasks = 1\n    if num_tasks >= 10:\n        save_after_every_n_tasks = int(num_tasks/10)\n\n    accuracies = torch.zeros(total_iters, dtype=torch.float)\n    weight_mag_sum = torch.zeros((total_iters, num_hidden_layers+1), dtype=torch.float)\n\n    rank_measure_period = 60000\n    effective_ranks = torch.zeros((int(total_examples/rank_measure_period), num_hidden_layers), dtype=torch.float)\n    approximate_ranks = torch.zeros((int(total_examples/rank_measure_period), num_hidden_layers), dtype=torch.float)\n    approximate_ranks_abs = torch.zeros((int(total_examples/rank_measure_period), num_hidden_layers), dtype=torch.float)\n    ranks = torch.zeros((int(total_examples/rank_measure_period), num_hidden_layers), dtype=torch.float)\n    dead_neurons = torch.zeros((int(total_examples/rank_measure_period), num_hidden_layers), dtype=torch.float)\n\n    iter = 0\n    with open('data/mnist_', 'rb+') as f:\n        x, y, _, _ = pickle.load(f)\n        if use_gpu == 1:\n            x = x.to(dev)\n            y = y.to(dev)\n\n    for task_idx in (range(num_tasks)):\n        new_iter_start = iter\n        pixel_permutation = np.random.permutation(input_size)\n        x = x[:, pixel_permutation]\n        data_permutation = np.random.permutation(examples_per_task)\n        x, y = x[data_permutation], y[data_permutation]\n\n        if agent_type != 'linear':\n            with torch.no_grad():\n                new_idx = int(iter / rank_measure_period)\n                m = net.predict(x[:2000])[1]\n                for rep_layer_idx in range(num_hidden_layers):\n                    ranks[new_idx][rep_layer_idx], effective_ranks[new_idx][rep_layer_idx], \\\n                    approximate_ranks[new_idx][rep_layer_idx], approximate_ranks_abs[new_idx][rep_layer_idx] = \\\n                        compute_matrix_rank_summaries(m=m[rep_layer_idx], use_scipy=True)\n                    dead_neurons[new_idx][rep_layer_idx] = (m[rep_layer_idx].abs().sum(dim=0) == 0).sum()\n                print('approximate rank: ', approximate_ranks[new_idx], ', dead neurons: ', dead_neurons[new_idx])\n\n        for start_idx in tqdm(range(0, change_after, mini_batch_size)):\n            start_idx = start_idx % examples_per_task\n            batch_x = x[start_idx: start_idx+mini_batch_size]\n            batch_y = y[start_idx: start_idx+mini_batch_size]\n\n            # train the network\n            loss, network_output = learner.learn(x=batch_x, target=batch_y)\n\n            if to_log and agent_type != 'linear':\n                for idx, layer_idx in enumerate(learner.net.layers_to_log):\n                    weight_mag_sum[iter][idx] = learner.net.layers[layer_idx].weight.data.abs().sum()\n            # log accuracy\n            with torch.no_grad():\n                accuracies[iter] = accuracy(softmax(network_output, dim=1), batch_y).cpu()\n            iter += 1\n\n        print('recent accuracy', accuracies[new_iter_start:iter - 1].mean())\n        if task_idx % save_after_every_n_tasks == 0:\n            data = {\n                'accuracies': accuracies.cpu(),\n                'weight_mag_sum': weight_mag_sum.cpu(),\n                'ranks': ranks.cpu(),\n                'effective_ranks': effective_ranks.cpu(),\n                'approximate_ranks': approximate_ranks.cpu(),\n                'abs_approximate_ranks': approximate_ranks_abs.cpu(),\n                'dead_neurons': dead_neurons.cpu(),\n            }\n            save_data(file=params['data_file'], data=data)\n\n    data = {\n        'accuracies': accuracies.cpu(),\n        'weight_mag_sum': weight_mag_sum.cpu(),\n        'ranks': ranks.cpu(),\n        'effective_ranks': effective_ranks.cpu(),\n        'approximate_ranks': approximate_ranks.cpu(),\n        'abs_approximate_ranks': approximate_ranks_abs.cpu(),\n        'dead_neurons': dead_neurons.cpu(),\n    }\n    save_data(file=params['data_file'], data=data)\n\n\ndef save_data(file, data):\n    with open(file, 'wb+') as f:\n        pickle.dump(data, f)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T20:26:54.971429Z","iopub.execute_input":"2023-10-01T20:26:54.971688Z","iopub.status.idle":"2023-10-01T20:26:54.998611Z","shell.execute_reply.started":"2023-10-01T20:26:54.971669Z","shell.execute_reply":"2023-10-01T20:26:54.997747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(f'temp_cfg/0.json', 'r') as f:\n    params = json.load(f)\n\n    online_expr(params)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:44:56.696232Z","iopub.execute_input":"2023-09-28T14:44:56.697076Z","iopub.status.idle":"2023-09-28T16:45:56.699920Z","shell.execute_reply.started":"2023-09-28T14:44:56.697038Z","shell.execute_reply":"2023-09-28T16:45:56.698771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from lop.utils.miscellaneous import *\nfrom lop.utils.plot_online_performance import generate_online_performance_plot\n\n\ndef add_cfg_performance(cfg='', setting_idx=0, m=2*10*1000, num_runs=30, metric='accuracy'):\n    with open(cfg, 'r') as f:\n        params = json.load(f)\n    list_params, param_settings = get_configurations(params=params)\n    per_param_setting_performance = []\n    for idx in range(num_runs):\n        file = params['data_dir'] + str(setting_idx) + '/' + str(idx)\n        with open(file, 'rb') as f:\n            data = pickle.load(f)\n\n        if metric == 'weight':\n            num_weights = 9588000\n            per_param_setting_performance.append(np.array(torch.Tensor.cpu(bin_m_errs(errs=data['weight_mag_sum'].sum(dim=1)/num_weights, m=m))))\n        elif metric == 'dead_neurons':\n            num_units = 3*2000\n            per_param_setting_performance.append(np.array(torch.Tensor.cpu(bin_m_errs(errs=data['dead_neurons'].sum(dim=1)/num_units*100, m=m))))\n        elif metric == 'effective_rank':\n            rank_normlization = 3*2000/100\n            per_param_setting_performance.append(np.array(torch.Tensor.cpu(bin_m_errs(errs=data['effective_ranks'].sum(dim=1)/rank_normlization, m=m))))\n        else:\n            per_param_setting_performance.append(np.array(torch.Tensor.cpu(bin_m_errs(errs=data['accuracies'] * 100, m=m))))\n    print(param_settings[setting_idx], setting_idx, np.array(per_param_setting_performance).mean())\n    return np.array(per_param_setting_performance)\n\ndef bp_metrics(cfg_file, metric):\n    with open(cfg_file, 'r') as f:\n        params = json.load(f)\n    list_params, param_settings = get_configurations(params=params)\n\n    performances = []\n    m = {'weight': 60*1000, 'accuracy': 60*1000, 'dead_neurons': 1, 'effective_rank': 1}[metric]\n    num_runs = 1\n\n    indices = [i for i in range(1)]\n    for i in indices:\n        performances.append(add_cfg_performance(cfg=cfg_file, setting_idx=i, m=m, num_runs=num_runs, metric=metric))\n    \n    print(performances)\n\n    yticks = {'weight': [0, 0.02, 0.04, 0.06, 0.08, 0.10], 'accuracy': [88, 90, 92, 94, 96],\n              'dead_neurons': [0, 10, 20, 30], 'effective_rank': [0, 10, 20, 30, 40, 50]}[metric]\n    generate_online_performance_plot(\n        performances=performances,\n        colors=['C1', 'C3', 'C5', 'C2', 'C4', 'C6'],\n        yticks=yticks,\n        xticks=[0, 15*m, 30*m, 45*m, 60*m],\n        xticks_labels=['0', '15', '30', '45', '60'],\n        m=m,\n        fontsize=18,\n        labels=param_settings,\n    )","metadata":{"execution":{"iopub.status.busy":"2023-10-01T20:26:55.000053Z","iopub.execute_input":"2023-10-01T20:26:55.000376Z","iopub.status.idle":"2023-10-01T20:26:55.014304Z","shell.execute_reply.started":"2023-10-01T20:26:55.000345Z","shell.execute_reply":"2023-10-01T20:26:55.013396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bp_metrics('/kaggle/working/lop/lop/permuted_mnist/cfg/bp/std_net.json', 'accuracy')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T16:45:56.728119Z","iopub.execute_input":"2023-09-28T16:45:56.729223Z","iopub.status.idle":"2023-09-28T16:45:57.487502Z","shell.execute_reply.started":"2023-09-28T16:45:56.729181Z","shell.execute_reply":"2023-09-28T16:45:57.486360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\ngraph = np.asarray(Image.open('comparison.png'))\nplt.imshow(graph)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T13:16:01.262973Z","iopub.execute_input":"2023-09-30T13:16:01.264099Z","iopub.status.idle":"2023-09-30T13:16:02.141462Z","shell.execute_reply.started":"2023-09-30T13:16:01.264057Z","shell.execute_reply":"2023-09-30T13:16:02.140199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_cfg('/kaggle/working/lop/lop/permuted_mnist/cfg/bp/small_net.json')\nwith open(f'temp_cfg/0.json', 'r') as f:\n    params = json.load(f)\n\n    online_expr(params)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T13:16:19.941539Z","iopub.execute_input":"2023-09-30T13:16:19.942269Z","iopub.status.idle":"2023-09-30T14:42:28.526224Z","shell.execute_reply.started":"2023-09-30T13:16:19.942230Z","shell.execute_reply":"2023-09-30T14:42:28.524727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bp_metrics('/kaggle/working/lop/lop/permuted_mnist/cfg/bp/small_net.json', 'accuracy')","metadata":{"execution":{"iopub.status.busy":"2023-09-30T14:44:57.271208Z","iopub.execute_input":"2023-09-30T14:44:57.271598Z","iopub.status.idle":"2023-09-30T14:44:57.924063Z","shell.execute_reply.started":"2023-09-30T14:44:57.271569Z","shell.execute_reply":"2023-09-30T14:44:57.923068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\ngraph = np.asarray(Image.open('comparison.png'))\nplt.imshow(graph)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T14:45:13.237980Z","iopub.execute_input":"2023-09-30T14:45:13.238427Z","iopub.status.idle":"2023-09-30T14:45:14.266552Z","shell.execute_reply.started":"2023-09-30T14:45:13.238392Z","shell.execute_reply":"2023-09-30T14:45:14.265552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_cfg('/kaggle/working/lop/lop/permuted_mnist/cfg/adam.json')\nwith open(f'temp_cfg/0.json', 'r') as f:\n    params = json.load(f)\n\n    online_expr(params)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T14:46:44.950366Z","iopub.execute_input":"2023-09-30T14:46:44.950769Z","iopub.status.idle":"2023-09-30T18:11:21.885242Z","shell.execute_reply.started":"2023-09-30T14:46:44.950740Z","shell.execute_reply":"2023-09-30T18:11:21.884089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bp_metrics('/kaggle/working/lop/lop/permuted_mnist/cfg/adam.json', 'accuracy')","metadata":{"execution":{"iopub.status.busy":"2023-09-30T18:20:57.449835Z","iopub.execute_input":"2023-09-30T18:20:57.450170Z","iopub.status.idle":"2023-09-30T18:20:58.030934Z","shell.execute_reply.started":"2023-09-30T18:20:57.450144Z","shell.execute_reply":"2023-09-30T18:20:58.030008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"graph = np.asarray(Image.open('comparison.png'))\nplt.imshow(graph)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T18:20:58.178110Z","iopub.execute_input":"2023-09-30T18:20:58.178995Z","iopub.status.idle":"2023-09-30T18:20:59.139745Z","shell.execute_reply.started":"2023-09-30T18:20:58.178955Z","shell.execute_reply":"2023-09-30T18:20:59.138859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir data/cbp\n!mkdir data/cbp/0","metadata":{"execution":{"iopub.status.busy":"2023-10-01T20:40:18.474378Z","iopub.execute_input":"2023-10-01T20:40:18.474765Z","iopub.status.idle":"2023-10-01T20:40:20.729638Z","shell.execute_reply.started":"2023-10-01T20:40:18.474738Z","shell.execute_reply":"2023-10-01T20:40:20.728112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg = {\n    \"model_version\": \"CBP on net with 3 hidden layer and 2000 hidden-units\",\n    \"num_runs\":  1,\n    \"num_tasks\": 60,\n    \"use_gpu\": 1,\n    \"data_dir\": \"data/cbp/0/\",\n    \"to_log\": True,\n\n    \"agent\": \"cbp\",\n    \"opt\": \"sgd\",\n    \"num_features\": 500,\n    \"num_hidden_layers\": 3,\n    \"step_size\": 0.003,\n    \"accumulate\": True,\n    \"util_type\": \"adaptable_contribution\",\n    \"replacement_rate\": 1e-4,\n    \"decay_rate\": 0.99,\n    \"mt\": 100,\n    \"index\": 0,\n    \"data_file\": \"data/cbp/0/0\"\n}\nonline_expr(cfg)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T20:40:23.574328Z","iopub.execute_input":"2023-10-01T20:40:23.575438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r res.zip /kaggle/working/data/bp","metadata":{"execution":{"iopub.status.busy":"2023-09-27T16:34:59.251653Z","iopub.status.idle":"2023-09-27T16:34:59.252216Z","shell.execute_reply.started":"2023-09-27T16:34:59.251953Z","shell.execute_reply":"2023-09-27T16:34:59.251977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\n\nFileLink(r'res.zip')","metadata":{},"execution_count":null,"outputs":[]}]}